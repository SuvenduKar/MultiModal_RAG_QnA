{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass, field\n",
    "from importlib import resources as resources\n",
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelCfg:\n",
    "    model: str = \"microsoft/Phi-3.5-vision-instruct\"\n",
    "    device_map: str = 'cpu'#'cuda'\n",
    "    torch_dtype: torch.dtype | str = torch.float32\n",
    "    model_kwargs: dict = field(default_factory=lambda: {'trust_remote_code':True, '_attn_implementation': 'flash_attention_2'})\n",
    "    #CHANGE _ATTN_IMPLENTATION TO 'eager' IF 'flash_attention_2' NOT SUPPORTED\n",
    "    processor_kwargs: dict = field(default_factory=lambda: {'trust_remote_code':True, 'num_crops':16})\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RetrievalCfg:\n",
    "    n_pages: int = 20\n",
    "    n_passages: int = 7\n",
    "    chunk_size: int = 300\n",
    "    chunk_overlap: int = 150\n",
    "    separators: list = field(default_factory=lambda: [\"\\n\\n\", \"\\n\", \".\", \",\"])\n",
    "    length_function: Callable = len\n",
    "    query_separator: str = 'Keywords: '\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EmbeddingModelCfg:\n",
    "    embedding_model_name: str = \"Snowflake/snowflake-arctic-embed-l\"\n",
    "    embedding_model_kwargs: dict = field(default_factory=lambda: {'device': 'cpu',\n",
    "                                                                  'model_kwargs': {'torch_dtype': torch.float32},\n",
    "                                                                  })\n",
    "    encode_kwargs: dict = field(default_factory=lambda: {'normalize_embeddings': True})\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RetrievedPassage:\n",
    "    passage: str\n",
    "    page: str\n",
    "    url: str\n",
    "\n",
    "\n",
    "class TemplateCfg(ABC):\n",
    "    template: str\n",
    "    generation_kwargs: dict\n",
    "\n",
    "    @abstractmethod\n",
    "    def format_template(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def load_template(file: str) -> str:\n",
    "    with resources.files(\"templates\").joinpath(file).open('r') as f:\n",
    "        instruction_template = f.read()\n",
    "    return instruction_template\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class KeywordGenerationCfg(TemplateCfg):\n",
    "    template: str = load_template(\"keyword_generation.txt\")\n",
    "    prompt_addition: str = 'Keywords: '\n",
    "    generation_kwargs: dict = field(default_factory=lambda: {'max_new_tokens': 64})\n",
    "\n",
    "    def format_template(self, question: str) -> str:\n",
    "        return self.template.format(question=question)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class QuestionAnsweringCfg(TemplateCfg):\n",
    "    qa_template: str = load_template('question_answering.txt')\n",
    "    passage_template: str = load_template('passage_quote.txt')\n",
    "    generation_kwargs: dict = field(default_factory=lambda: {'max_new_tokens': 256})\n",
    "    model_answer_split: str = 'Assistant: '\n",
    "\n",
    "    def format_template(self, question: str, retrieval_results: list[RetrievedPassage]) -> str:\n",
    "        retrieved = ''\n",
    "        for result in retrieval_results:\n",
    "            retrieved += self.passage_template.format(page=result.page, passage=result.passage)\n",
    "        return self.qa_template.format(passages=retrieved, question=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiki Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import wikipedia\n",
    "from wikipedia import WikipediaPage\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class WikipediaRetriever:\n",
    "    def __init__(self,\n",
    "                 embedding_cfg: EmbeddingModelCfg = EmbeddingModelCfg(),\n",
    "                 ):\n",
    "        self.embeddings_cfg = embedding_cfg\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=embedding_cfg.embedding_model_name,\n",
    "                                                model_kwargs=embedding_cfg.embedding_model_kwargs,\n",
    "                                                encode_kwargs=embedding_cfg.encode_kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def find_pages(keywords: str, n_pages: int) -> list[WikipediaPage]:\n",
    "        titles = wikipedia.search(keywords, results=n_pages)\n",
    "        pages = []\n",
    "        for t in titles:\n",
    "            try:\n",
    "                pages.append(wikipedia.page(t, auto_suggest=False))\n",
    "            except Exception as e:\n",
    "                warnings.warn(str(e))\n",
    "        return pages\n",
    "\n",
    "    def select_passages(self,\n",
    "                        pages: list[WikipediaPage],\n",
    "                        question: str,\n",
    "                        keywords: str,\n",
    "                        retrieval_cfg: RetrievalCfg) -> list[RetrievedPassage]:\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=retrieval_cfg.chunk_size,\n",
    "                                                  chunk_overlap=retrieval_cfg.chunk_overlap,\n",
    "                                                  length_function=retrieval_cfg.length_function,\n",
    "                                                  )\n",
    "        page_splits = splitter.create_documents(texts=[p.content for p in pages],\n",
    "                                                metadatas=[{'page_no': i} for i in range(len(pages))])\n",
    "        db = FAISS.from_documents(page_splits, self.embeddings)\n",
    "        docs = db.similarity_search(question + retrieval_cfg.query_separator + keywords,\n",
    "                                    k=retrieval_cfg.n_passages)\n",
    "        return [RetrievedPassage(passage=docs[i].page_content,\n",
    "                                 page=pages[docs[i].metadata['page_no']].title,\n",
    "                                 url=pages[docs[i].metadata['page_no']].url)\n",
    "                for i in range(retrieval_cfg.n_passages)]\n",
    "\n",
    "    def __call__(self,\n",
    "                 question: str,\n",
    "                 keywords: str,\n",
    "                 retrieval_cfg: RetrievalCfg) -> list[RetrievedPassage]:\n",
    "        pages = self.find_pages(keywords, n_pages=retrieval_cfg.n_pages)\n",
    "        if len(pages) < 1:\n",
    "            warnings.warn(f\"Unable to retrieve any page with the keywords {keywords}\")\n",
    "            selected_passages = []\n",
    "        else:\n",
    "            selected_passages = self.select_passages(pages=pages,\n",
    "                                                     question=question,\n",
    "                                                     keywords=keywords,\n",
    "                                                     retrieval_cfg=retrieval_cfg)\n",
    "        return selected_passages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sk731\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from transformers.image_utils import load_image\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def format_messages(prompt: str) -> list:\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"<|image_1|>\\n\" + prompt,\n",
    "    }\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "\n",
    "class VisualQuestionRAG:\n",
    "    \"\"\"Pipeline for Visual Question Answering with Retrieval Augmented Generation from Wikipedia.\n",
    "       Attributes:\n",
    "             cfg: the model configuration.\n",
    "             model: the loaded Vision Language Model.\n",
    "             processor: the huggingface transformers' processor for the VLM.\n",
    "             retriever: an instance of the Wikipedia retriever to be used for retrieval.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 retriever: WikipediaRetriever,\n",
    "                 cfg: ModelCfg = ModelCfg(),\n",
    "                 ):\n",
    "        self.cfg = cfg\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(cfg.model,\n",
    "                                                          torch_dtype=cfg.torch_dtype,\n",
    "                                                          device_map=cfg.device_map,\n",
    "                                                          **cfg.model_kwargs)\n",
    "        self.processor = AutoProcessor.from_pretrained(cfg.model, **cfg.processor_kwargs)\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def generate(self,\n",
    "                 prompt: str,\n",
    "                 img: Image.Image,\n",
    "                 **kwargs) -> str:\n",
    "        messages = format_messages(prompt)\n",
    "        text = self.processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        inputs = self.processor(text, [img], return_tensors=\"pt\").to(self.model.device)\n",
    "        generated_tokens = self.model.generate(**inputs,\n",
    "                                               eos_token_id=self.processor.tokenizer.eos_token_id,\n",
    "                                               **kwargs)[:, inputs['input_ids'].shape[1]:]\n",
    "        generated_text = self.processor.batch_decode(generated_tokens,\n",
    "                                                     skip_special_tokens=True,\n",
    "                                                     clean_up_tokenization_spaces=False)[0]\n",
    "\n",
    "        return generated_text\n",
    "\n",
    "    def generate_keywords(self,\n",
    "                          query: str,\n",
    "                          img: str | Image.Image,\n",
    "                          template: KeywordGenerationCfg = KeywordGenerationCfg(),\n",
    "                          ) -> str:\n",
    "        prompt = template.format_template(query)\n",
    "        generated_text = self.generate(prompt=prompt, img=img, **template.generation_kwargs)\n",
    "        return generated_text\n",
    "\n",
    "    def rag_question_answering(self,\n",
    "                               question: str,\n",
    "                               retrieval_results: list[RetrievedPassage],\n",
    "                               img: str | Image.Image,\n",
    "                               template: QuestionAnsweringCfg = QuestionAnsweringCfg(),\n",
    "                               ) -> str:\n",
    "        prompt = template.format_template(question=question, retrieval_results=retrieval_results)\n",
    "        generated_text = self.generate(prompt=prompt,\n",
    "                                       img=img,\n",
    "                                       **template.generation_kwargs)\n",
    "        return generated_text\n",
    "\n",
    "    def __call__(self,\n",
    "                 question: str,\n",
    "                 img_or_img_path: str | Image.Image,\n",
    "                 keyword_generation_cfg: KeywordGenerationCfg = KeywordGenerationCfg(),\n",
    "                 retrieval_cfg: RetrievalCfg = RetrievalCfg(),\n",
    "                 answer_generation_cfg: QuestionAnsweringCfg = QuestionAnsweringCfg(),\n",
    "                 ) -> tuple[str, str, list[RetrievedPassage]]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            question: The user's question.\n",
    "            img_or_img_path: If a string, the image will be loaded from the path or url. Otherwise, a PIL Image object\n",
    "                             is accepted.\n",
    "            keyword_generation_cfg: an instance of the KeywordGenerationCfg class. It specifies the configuration for\n",
    "                                    keyword generation.\n",
    "            retrieval_cfg: an instance of the RetrievalCfg class. It specifies the configuration for passage retrieval.\n",
    "            answer_generation_cfg: an instance of the QuestionAnsweringCfg class. It specifies the configuration for the\n",
    "                                   generation of the retrieval augmented answer.\n",
    "\n",
    "\n",
    "        Returns:\n",
    "           A tuple containing the answer to the user's question, the keywords used for retrieval, and the selected\n",
    "           passages.\n",
    "\n",
    "        \"\"\"\n",
    "        img = load_image(img_or_img_path)\n",
    "        keywords = self.generate_keywords(query=question, img=img, template=keyword_generation_cfg)\n",
    "        selected_passages = self.retriever(question=question, keywords=keywords, retrieval_cfg=retrieval_cfg)\n",
    "        answer = self.rag_question_answering(question=question,\n",
    "                                             img=img,\n",
    "                                             retrieval_results=selected_passages,\n",
    "                                             template=answer_generation_cfg)\n",
    "        return answer, keywords, selected_passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = ModelCfg(model=\"microsoft/Phi-3.5-vision-instruct\",\n",
    "               model_kwargs={'trust_remote_code':True, '_attn_implementation': 'eager'},\n",
    "               processor_kwargs={'trust_remote_code':True, 'num_crops':16},\n",
    "               device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0e50c0221c4ddea775184f08e74e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "C:\\Users\\sk731\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\auto\\image_processing_auto.py:513: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "retriever = WikipediaRetriever()\n",
    "model = VisualQuestionRAG(retriever, cfg=cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep  4 22:24:09 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.76                 Driver Version: 551.76         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   47C    P8             12W /   30W |    6105MiB /   8192MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     36172      C   C:\\Program Files\\Python311\\python.exe       N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "question = \"How much does this species weight?\"\n",
    "img = \"https://images.unsplash.com/photo-1589656966895-2f33e7653819?utm_medium=medium&w=700&q=50&auto=format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "C:\\Users\\sk731\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\clip\\modeling_clip.py:480: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    }
   ],
   "source": [
    "answer, keywords, selected_passages = model(question=question, img_or_img_path=img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model's Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weight of this species, the polar bear, ranges from 300-800 kg (660-1,760 lb) for males and 150-300 kg (330-660 lb) for females.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'polar bear, weight'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From page Polar bear (https://en.wikipedia.org/wiki/Polar_bear): \n",
      " \"Males are generally 200–250 cm (6.6–8.2 ft) long with a weight of 300–800 kg (660–1,760 lb). Females are smaller at 180–200 cm (5.9–6.6 ft) with a weight of 150–300 kg (330–660 lb). Sexual dimorphism in the species is particularly high compared with most other mammals. Male polar bears also have\".\n",
      "From page Polar bear (https://en.wikipedia.org/wiki/Polar_bear): \n",
      " \"== Notes ==\n",
      "\n",
      "\n",
      "== References ==\n",
      "\n",
      "\n",
      "== Bibliography ==\n",
      "\n",
      "\n",
      "== External links ==\n",
      "Polar Bears International website\n",
      "ARKive—images and movies of the polar bear (Ursus maritimus)\".\n",
      "From page Polar bear (https://en.wikipedia.org/wiki/Polar_bear): \n",
      " \"weight of 150–300 kg (330–660 lb). Sexual dimorphism in the species is particularly high compared with most other mammals. Male polar bears also have proportionally larger heads than females. The weight of polar bears fluctuates during the year, as they can bulk up on fat and increase their mass by\".\n",
      "From page List of ursids (https://en.wikipedia.org/wiki/List_of_ursids): \n",
      " \"long, plus a 3–20 cm (1–8 in) tail, though the polar bear is 2.2–2.44 m (7–8 ft) long, and some subspecies of brown bear can be up to 2.8 m (9 ft). Weights range greatly from the sun bear, which can be as low as 35 kg (77 lb), to the polar bear, which can be as high as 726 kg (1,600 lb). Population\".\n",
      "From page Knut (polar bear) (https://en.wikipedia.org/wiki/Knut_(polar_bear)): \n",
      " \"== See also ==\n",
      "Binky (polar bear)\n",
      "List of individual bears\n",
      "\n",
      "\n",
      "== References ==\n",
      "\n",
      "\n",
      "== External links ==\".\n",
      "From page Polar bear (https://en.wikipedia.org/wiki/Polar_bear): \n",
      " \"The polar bear is the largest living species of bear and land carnivore, though some brown bear subspecies like the Kodiak bear can rival it in size. Males are generally 200–250 cm (6.6–8.2 ft) long with a weight of 300–800 kg (660–1,760 lb). Females are smaller at 180–200 cm (5.9–6.6 ft) with a\".\n",
      "From page Subspecies of brown bear (https://en.wikipedia.org/wiki/Subspecies_of_brown_bear): \n",
      " \"males, potentially tripling their average weight within three years' time, and can expect to average between 360 and 545 kg (794 and 1,202 lb). The reported mean adult body masses for both sexes of the polar bear are very similar to the peninsular giant and Kodiak bears. Due to their roughly\".\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for p in selected_passages:\n",
    "  print(f\"\"\"From page {p.page} ({p.url}): \\n \"{p.passage}\".\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Polar bears can weigh between 900 to 1,600 pounds (408 to 727 kilograms).'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from transformers.image_utils import load_image\n",
    "\n",
    "\n",
    "model.generate(question, load_image(img), max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
